{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b977feea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://EM2021002842.bosonit.local:4041\n",
       "SparkContext available as 'sc' (version = 3.1.1, master = local[*], app id = local-1629458267514)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "julio: String = NASA_Access_Log_Jul95.gz\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val julio = \"NASA_Access_Log_Jul95.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d56db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@6c49d9f0\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession\n",
    ".builder\n",
    ".appName(\"Nasa\")\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeb425b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nasaLogsJulio: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string ... 6 more fields]\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nasaLogsJulio = spark.read.option(\"sep\",\" \").csv(julio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecfa6723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+---+---------------------+------+-----------------------------+---+----+\n",
      "|_c0         |_c1|_c2|_c3                  |_c4   |_c5                          |_c6|_c7 |\n",
      "+------------+---+---+---------------------+------+-----------------------------+---+----+\n",
      "|199.72.81.55|-  |-  |[01/Jul/1995:00:00:01|-0400]|GET /history/apollo/ HTTP/1.0|200|6245|\n",
      "+------------+---+---+---------------------+------+-----------------------------+---+----+\n",
      "only showing top 1 row\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "nasaLogsJulio.show(1,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8550da6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.regexp_replace\r\n",
       "nasaLogsJulio1: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string ... 6 more fields]\r\n",
       "nasaLogsJulio2: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string ... 6 more fields]\r\n",
       "nasaLogsJulio3: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string ... 7 more fields]\r\n",
       "nasaLogsJulio4: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string ... 8 more fields]\r\n",
       "nasaLogsJulio5: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string ... 9 more fields]\r\n",
       "nasaLogsJulio6: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string ... 8 more fields]\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.regexp_replace\n",
    "\n",
    "val nasaLogsJulio1 = nasaLogsJulio.withColumn(\"_c3\", regexp_replace($\"_c3\", \"\\\\[\", \"\"))\n",
    "val nasaLogsJulio2 = nasaLogsJulio1.withColumn(\"_c4\", regexp_replace($\"_c4\", \"\\\\]\", \"\"))\n",
    "val nasaLogsJulio3 = nasaLogsJulio2.withColumn(\"RequestMethod\", regexp_replace($\"_c5\", \"(\\\\w+).*\", \"$1\"))\n",
    "val nasaLogsJulio4 = nasaLogsJulio3.withColumn(\"Resource\", regexp_replace($\"_c5\", \"\\\\S+\\\\s(\\\\S+).*\", \"$1\"))\n",
    "val nasaLogsJulio5 = nasaLogsJulio4.withColumn(\"Protocol\", regexp_replace($\"_c5\", \"\\\\S+\\\\s+\\\\S+\\\\s(\\\\S+).*\", \"$1\"))\n",
    "val nasaLogsJulio6 = nasaLogsJulio5.drop(\"_c5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b020d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+---+--------------------+-----+---+----+-------------+----------------+--------+\n",
      "|_c0         |_c1|_c2|_c3                 |_c4  |_c6|_c7 |RequestMethod|Resource        |Protocol|\n",
      "+------------+---+---+--------------------+-----+---+----+-------------+----------------+--------+\n",
      "|199.72.81.55|-  |-  |01/Jul/1995:00:00:01|-0400|200|6245|GET          |/history/apollo/|HTTP/1.0|\n",
      "+------------+---+---+--------------------+-----+---+----+-------------+----------------+--------+\n",
      "only showing top 1 row\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "nasaLogsJulio6.show(1,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03564205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nasaLogsJulio7: org.apache.spark.sql.DataFrame = [Host: string, UserIdentifier: string ... 8 more fields]\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nasaLogsJulio7 = nasaLogsJulio6.withColumnRenamed(\"_c0\", \"Host\")\n",
    "                             .withColumnRenamed(\"_c1\", \"UserIdentifier\")\n",
    "                             .withColumnRenamed(\"_c2\", \"UserId\")\n",
    "                             .withColumnRenamed(\"_c4\", \"TimeZone\")\n",
    "                             .withColumnRenamed(\"_c6\", \"HttpStatus\")\n",
    "                             .withColumnRenamed(\"_c7\", \"Size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ecaf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+------+--------------------+--------+----------+----+-------------+----------------+--------+\n",
      "|Host        |UserIdentifier|UserId|_c3                 |TimeZone|HttpStatus|Size|RequestMethod|Resource        |Protocol|\n",
      "+------------+--------------+------+--------------------+--------+----------+----+-------------+----------------+--------+\n",
      "|199.72.81.55|-             |-     |01/Jul/1995:00:00:01|-0400   |200       |6245|GET          |/history/apollo/|HTTP/1.0|\n",
      "+------------+--------------+------+--------------------+--------+----------+----+-------------+----------------+--------+\n",
      "only showing top 1 row\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "nasaLogsJulio7.show(1,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d2cc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nasaLogs5: org.apache.spark.sql.DataFrame = [Host: string, UserIdentifier: string ... 9 more fields]\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nasaLogs5 = nasaLogsJulio7.withColumn(\"DateTime\", to_timestamp($\"_c3\", \"dd/MMM/yyyy:HH:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f39ce84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Host: string (nullable = true)\n",
      " |-- UserIdentifier: string (nullable = true)\n",
      " |-- UserId: string (nullable = true)\n",
      " |-- TimeZone: string (nullable = true)\n",
      " |-- HttpStatus: string (nullable = true)\n",
      " |-- Size: string (nullable = true)\n",
      " |-- RequestMethod: string (nullable = true)\n",
      " |-- Resource: string (nullable = true)\n",
      " |-- Protocol: string (nullable = true)\n",
      " |-- DateTime: timestamp (nullable = true)\n",
      "\n",
      "+------------+--------------+------+--------+----------+----+-------------+----------------+--------+-------------------+\n",
      "|Host        |UserIdentifier|UserId|TimeZone|HttpStatus|Size|RequestMethod|Resource        |Protocol|DateTime           |\n",
      "+------------+--------------+------+--------+----------+----+-------------+----------------+--------+-------------------+\n",
      "|199.72.81.55|-             |-     |-0400   |200       |6245|GET          |/history/apollo/|HTTP/1.0|1995-07-01 00:00:01|\n",
      "+------------+--------------+------+--------+----------+----+-------------+----------------+--------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nasaLogs4: org.apache.spark.sql.DataFrame = [Host: string, UserIdentifier: string ... 8 more fields]\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nasaLogs4 = nasaLogs5.drop(\"_c3\")\n",
    "nasaLogs4.printSchema()\n",
    "nasaLogs4.show(1,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9a513cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\r\n",
       "nasaLogs3: org.apache.spark.sql.DataFrame = [Host: string, UserIdentifier: string ... 9 more fields]\r\n",
       "nasaLogs2: org.apache.spark.sql.DataFrame = [Host: string, UserIdentifier: string ... 10 more fields]\r\n",
       "nasaLogs1: org.apache.spark.sql.DataFrame = [Host: string, UserIdentifier: string ... 9 more fields]\r\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val nasaLogs3 = nasaLogs4.withColumn(\"Date\",to_date($\"DateTime\"))\n",
    "val nasaLogs2 = nasaLogs3.withColumn(\"Time\",date_format($\"DateTime\", \"HH:mm:ss\"))\n",
    "val nasaLogs1 = nasaLogs2.drop(\"DateTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3856025d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nasaLogs: org.apache.spark.sql.DataFrame = [Host: string, UserIdentifier: string ... 9 more fields]\r\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nasaLogs = nasaLogs1.select(\"Host\",\"UserIdentifier\",\"UserId\",\"Date\",\"Time\",\"TimeZone\",\"RequestMethod\",\"Resource\",\"Protocol\",\n",
    "                                     \"HttpStatus\",\"Size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e372862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Host: string (nullable = true)\n",
      " |-- UserIdentifier: string (nullable = true)\n",
      " |-- UserId: string (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- TimeZone: string (nullable = true)\n",
      " |-- RequestMethod: string (nullable = true)\n",
      " |-- Resource: string (nullable = true)\n",
      " |-- Protocol: string (nullable = true)\n",
      " |-- HttpStatus: string (nullable = true)\n",
      " |-- Size: string (nullable = true)\n",
      "\n",
      "+------------+--------------+------+----------+--------+--------+-------------+----------------+--------+----------+----+\n",
      "|Host        |UserIdentifier|UserId|Date      |Time    |TimeZone|RequestMethod|Resource        |Protocol|HttpStatus|Size|\n",
      "+------------+--------------+------+----------+--------+--------+-------------+----------------+--------+----------+----+\n",
      "|199.72.81.55|-             |-     |1995-07-01|00:00:01|-0400   |GET          |/history/apollo/|HTTP/1.0|200       |6245|\n",
      "+------------+--------------+------+----------+--------+--------+-------------+----------------+--------+----------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nasaLogs.printSchema()\n",
    "nasaLogs.show(1,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ab2d6e",
   "metadata": {},
   "source": [
    "Consultas a realizar:  \n",
    "    1) - ¿Cuáles son los distintos protocolos web utilizados? Agrúpalos.  \n",
    "    2) - ¿Cuáles son los códigos de estado más comunes en la web? Agrúpalos y ordénalos para ver cuál es el más común.  \n",
    "    3) - ¿Y los métodos de petición (verbos) más utilizados?  \n",
    "    4) - ¿Qué recurso tuvo la mayor transferencia de bytes de la página web?  \n",
    "    5) - Además, queremos saber que recurso de nuestra web es el que más tráfico recibe. Es decir, el recurso con más registros \n",
    "         en nuestro log.  \n",
    "    6) - ¿Qué días la web recibió más tráfico?  \n",
    "    7) - ¿Cuáles son los hosts son los más frecuentes?  \n",
    "    8) - ¿A qué horas se produce el mayor número de tráfico en la web?  \n",
    "    9) - ¿Cuál es el número de errores 404 que ha habido cada día?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df51ea4c",
   "metadata": {},
   "source": [
    "### Respuestas:  \n",
    "1) - ¿Cuáles son los distintos protocolos web utilizados? Agrúpalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "275dfae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uno1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Protocol: string, count: bigint]\r\n",
       "uno: org.apache.spark.sql.DataFrame = [Protocol: string, count: bigint ... 1 more field]\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val uno1 = nasaLogs.groupBy(\"Protocol\").count().limit(1)\n",
    "val uno = uno1.withColumn(\"Consulta\", lit(\"Protocolo mas usado\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb13926",
   "metadata": {},
   "source": [
    "2) - ¿Cuáles son los códigos de estado más comunes en la web? Agrúpalos y ordénalos para ver cuál es el más común."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e6951aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dos1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [HttpStatus: string, count: bigint]\r\n",
       "dos: org.apache.spark.sql.DataFrame = [HttpStatus: string, count: bigint ... 1 more field]\r\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dos1 = nasaLogs.groupBy(\"HttpStatus\").count().sort(col(\"count\").desc).limit(1)\n",
    "val dos = dos1.withColumn(\"Consulta\", lit(\"HttpStatus mas comun\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3bcb8b",
   "metadata": {},
   "source": [
    "3) - ¿Y los métodos de petición (verbos) más utilizados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68401439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tres1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [RequestMethod: string, count: bigint]\r\n",
       "tres: org.apache.spark.sql.DataFrame = [RequestMethod: string, count: bigint ... 1 more field]\r\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tres1 = nasaLogs.groupBy(\"RequestMethod\").count().sort(col(\"count\").desc).limit(1)\n",
    "val tres = tres1.withColumn(\"Consulta\", lit(\"RequestMethod mas utilizado\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fcaed2",
   "metadata": {},
   "source": [
    "4) - ¿Qué recurso tuvo la mayor transferencia de bytes de la página web?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4e03461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuatro1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Resource: string, Size: string]\r\n",
       "cuatro: org.apache.spark.sql.DataFrame = [Resource: string, Size: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cuatro1 = nasaLogs.select(col(\"Resource\"), col(\"Size\")).orderBy(col(\"Size\").desc).limit(1)\n",
    "val cuatro = cuatro1.withColumn(\"Consulta\", lit(\"Resource con mas transferencia de bytes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14346b88",
   "metadata": {},
   "source": [
    "5) - Además, queremos saber que recurso de nuestra web es el que más tráfico recibe. Es decir, el recurso con más registros \n",
    "         en nuestro log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4d32422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cinco1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Resource: string, count: bigint]\r\n",
       "cinco: org.apache.spark.sql.DataFrame = [Resource: string, count: bigint ... 1 more field]\r\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cinco1 = nasaLogs.groupBy(\"Resource\").count().sort(col(\"count\").desc).limit(1)\n",
    "val cinco = cinco1.withColumn(\"Consulta\", lit(\"Resource con mas registros\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fbc1c6",
   "metadata": {},
   "source": [
    "6) - ¿Qué días la web recibió más tráfico?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe45b228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seis1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Dia: string, Trafico: bigint]\r\n",
       "seis: org.apache.spark.sql.DataFrame = [Dia: string, Trafico: bigint ... 1 more field]\r\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val seis1 = nasaLogs.select(date_format($\"Date\",\"d\").alias(\"Dia\"))\n",
    "                                .groupBy(col(\"Dia\"))\n",
    "                                .agg(count(\"*\").alias(\"Trafico\"))\n",
    "                                .orderBy(col(\"Trafico\").desc)\n",
    "                                .limit(1)\n",
    "val seis = seis1.withColumn(\"Consulta\", lit(\"Dia con mas trafico\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2febdc9a",
   "metadata": {},
   "source": [
    "7) - ¿Cuáles son los hosts más frecuentes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "656969c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "siete1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Host: string, count: bigint]\r\n",
       "siete: org.apache.spark.sql.DataFrame = [Host: string, count: bigint ... 1 more field]\r\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val siete1 = nasaLogs.groupBy(\"Host\").count().sort(col(\"count\").desc).limit(1)\n",
    "val siete = siete1.withColumn(\"Consulta\", lit(\"Host mas frecuente\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ba790",
   "metadata": {},
   "source": [
    "8) - ¿A qué horas se produce el mayor número de tráfico en la web?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "228e3e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ocho1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Hora: string, Trafico: bigint]\r\n",
       "ocho: org.apache.spark.sql.DataFrame = [Hora: string, Trafico: bigint ... 1 more field]\r\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ocho1 = nasaLogs.select(date_format($\"Time\",\"H\").alias(\"Hora\"))\n",
    "                                .groupBy(col(\"Hora\"))\n",
    "                                .agg(count(\"*\").alias(\"Trafico\"))\n",
    "                                .orderBy(col(\"Trafico\").desc)\n",
    "                                .limit(1)\n",
    "val ocho = ocho1.withColumn(\"Consulta\", lit(\"Hora con mayor trafico\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce620ea",
   "metadata": {},
   "source": [
    "9) - ¿Cuál es el número de errores 404 que ha habido cada día?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c4c20f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nueve1: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Dia: string, Errores: bigint]\r\n",
       "nueve: org.apache.spark.sql.DataFrame = [Dia: string, Errores: bigint ... 1 more field]\r\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nueve1 = nasaLogs.select(date_format($\"Date\",\"d\").alias(\"Dia\"),col(\"HttpStatus\"))\n",
    "                                .where(col(\"HttpStatus\") === 404)\n",
    "                                .groupBy(col(\"Dia\"))\n",
    "                                .agg(count(\"*\").alias(\"Errores\"))\n",
    "                                .orderBy(col(\"Errores\").desc)\n",
    "                                .limit(1)\n",
    "val nueve = nueve1.withColumn(\"Consulta\", lit(\"Dia con mayor numero de error 404\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6940c57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diez: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Protocol: string, count: bigint ... 1 more field]\r\n",
       "once: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Protocol: string, count: bigint ... 1 more field]\r\n",
       "doce: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Protocol: string, count: string ... 1 more field]\r\n",
       "trece: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Protocol: string, count: string ... 1 more field]\r\n",
       "catorce: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Protocol: string, count: string ... 1 more field]\r\n",
       "quince: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Protocol: string, count: string ... 1 more field]\r\n",
       "dieciseis: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Protocol: string, count: string ...\r\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val diez = uno.union(dos)\n",
    "val once = diez.union(tres)\n",
    "val doce = once.union(cuatro)\n",
    "val trece = doce.union(cinco)\n",
    "val catorce = trece.union(seis)\n",
    "val quince = catorce.union(siete)\n",
    "val dieciseis = quince.union(ocho)\n",
    "val diecisiete = dieciseis.union(nueve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09c0b9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dieciocho: org.apache.spark.sql.DataFrame = [Respuesta: string, count: string ... 1 more field]\r\n",
       "diecinueve: org.apache.spark.sql.DataFrame = [Consulta: string, Respuesta: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dieciocho = diecisiete.withColumnRenamed(\"Protocol\",\"Respuesta\")\n",
    "val diecinueve = dieciocho.select(\"Consulta\", \"Respuesta\", \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "425d57d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+------------------------------+-------+\n",
      "|Consulta                               |Respuesta                     |count  |\n",
      "+---------------------------------------+------------------------------+-------+\n",
      "|Protocolo mas usado                    |GET /ksc.html                 |159    |\n",
      "|HttpStatus mas comun                   |200                           |1701534|\n",
      "|RequestMethod mas utilizado            |GET                           |1887643|\n",
      "|Resource con mas transferencia de bytes|/images/cdrom-1-95/img0007.jpg|99981  |\n",
      "|Resource con mas registros             |/images/NASA-logosmall.gif    |111388 |\n",
      "|Dia con mas trafico                    |13                            |134203 |\n",
      "|Host mas frecuente                     |piweba3y.prodigy.com          |17572  |\n",
      "|Hora con mayor trafico                 |14                            |122479 |\n",
      "|Dia con mayor numero de error 404      |6                             |640    |\n",
      "+---------------------------------------+------------------------------+-------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "diecinueve.show(truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca174211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
